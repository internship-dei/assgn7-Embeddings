{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLLECTING .JSON FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = 'dataset'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['web-1.json',\n",
       " 'web-10034.json',\n",
       " 'web-10047.json',\n",
       " 'web-1005.json',\n",
       " 'web-10089.json',\n",
       " 'web-10133.json',\n",
       " 'web-10165.json',\n",
       " 'web-2012.json',\n",
       " 'web-3.json',\n",
       " 'web-4.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LIST OF .JSON FILES\n",
    "json_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACTING TEXT FROM EACH .JSON FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for index, js in enumerate(json_files):\n",
    "    with open(os.path.join(path_to_json, js)) as json_file:\n",
    "        json_text = json.load(json_file)\n",
    "    text.append(json_text['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STORING ORIGINAL TEXT\n",
    "raw_text = []\n",
    "for i in range(10):\n",
    "    string = ' '.join(str(item) for item in text[i])\n",
    "    raw_text.append(string.strip().split('\\n'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021 Coachmen Sportscoach 402TS Two Full Bath, Bunk Beds,Theater Seating, King, W/D going back Back California Privacy Rights California Consumer Privacy Act Notice for California Consumers 800-335-6054 817-790-7771 Sitemap This page took too long to load. Please try refreshing or  going back  to the previous page. All material copyright Â© Motor Home Specialist ( MHSRV.com ). All rights are reserved. No part of any material on this web site may be reproduced, distributed, or transmitted in any form or by any means without the prior written permission of Motor Home Specialist. *Information deemed reliable, but not guaranteed. Features & options subject to change without notice. Weights & measurements are estimates only. Verify before purchase. ',\n",
       " '         *DISCLAIMER: ',\n",
       " '        *#1 in the world or #1 in Texas references are per the official Stats Surveys Inc. for American built Motorhomes sold at single location. *MINIMUM 25% OFF MSRP DISCOUNT DOES NOT APPLY TO CLASS B RVS, FORESTER, DYNAMAX OR TWILIGHT PRODUCTS. The % discount shown on a unit is rounded to the nearest \"whole number\" percentage. The sale price is fractionally higher or lower than the percentage shown. All sale prices include any and all other incentives, offers and rebates offered by MHSRV or any other manufacturer unless specified in writing. Motor Home Specialist\\'s prices, sales and offers are subject to change without notice and Motor Home Specialist reserves the right to price any unit, including those spotlighted or specially marked, before, during or after a sale or promotion of any kind or type of advertisement including that of an email blast, TV spot, written ad or any other type of advertisement at any price they wish after any sale or promotion ends to ultimately sell every unit. *(w.a.c.) Estimated payment figured at 5.99% on 20 yrs with 10% down on units above $49,001. Units below $49,000, estimated payment figured at 5.99% on 15yrs with 10% down. Price and payment do NOT include TT&L or any other fees that may apply. Used units and RVs under $50K are subject to shorter terms, higher rates and restrictions. Call MHSRV\\'s finance department for complete details. Some videos and photos may not represent actual vehicle for sale. Manufacturer\\'s standards and features subject to change without notice. ALL weights, measurements, sizes, etc. including, but not limited to, TVs, bed sizes, tank capacities, lengths, GVWRs, etc., are all either estimated or information provided by the manufacturer and not guaranteed to be 100% accurate by MHSRV or the manufacturer due to continual product changes and enhancements. Any and all deposits are NON-REFUNDABLE unless otherwise specified in writing. Upon receipt of deposit seller (MHSRV) agrees to hold the selected unit and prepare it for delivery and orientation to the buyer. Buyer understands and agrees that by leaving said NON-REFUNDABLE deposit they are asking MHS to prepare their purchase for delivery and orientation and should they fail to pay for their purchase by the specified delivery date they will forfeit the NON-REFUNDABLE deposit. MHS retains the right to apply any or all of said NON-REFUNDABLE deposit to a future purchase. Online info deemed reliable, but not guaranteed. All materials are copyrighted by Motor Home Specialist (MHSRV.com). All rights are reserved. No part of any material on this website may be reproduced, distributed, or transmitted in any form or by any means without the prior written permission of Motor Home Specialist. *Up to 40% off example: 2019 American Coach Dream #MAC032018023 - MSRP $555,949 - 42% = MHSRV price $319,999 *Up to 45% off example: 2020 Thor Motor Coach Tuscany #JTH062050020 - MSRP $685,913 - 46% = MHSRV price $369,999. Thank you so much for shopping with us at Motor Home Specialist. If you have any further questions about sale prices, promotions, finance, etc. please call 800-335-6054 or local 817-790-7771. 100 OBanion Way Alvarado, TX. 76009.View your  California Privacy Rights . View the  California Consumer Privacy Act Notice for California Consumers .',\n",
       " '',\n",
       " '     5411 South I-35W Alvarado, Texas 76009 \\ue0cd Toll Free: \\ue324 Metro: \\ue8ad Fax: 800-335-6054 817-790-7771 817-783-6395 Mon-Sat: Sunday: 9:00a - 6:00p Closed Sitemap ZGzTRR59OdzWHHik021OZLP48ndjjPPG1VVOZZPz width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0 text/html; charset=utf-8 https://mhsrv.com/images/logo/logo--mhsrv-main-20th.png en-US website https://mhsrv.com/2021-coachmen-402ts-two-full-bath--bunk-beds-theater-seating--king--w-d-new-diesel-pusher-tx-i2732487/images MHSRV summary_large_image https://mhsrv.com/images/logo/logo--mhsrv-main-20th.png OeMESq4peMtcgW9SDbtyrN9ydsMmiWrsNpadArn_vfw _CDlWMYBCP7NSuA3dupW2bxGBwYTPs4E15coejG2ZHE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO REMOVE STOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pragati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('n')\n",
    "stop_words.append('r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOR LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOR STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOR BIGRAM FORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_text = []     #TO STORE THE PROCESSED DATA\n",
    "\n",
    "bigrams = []    \n",
    "for t in raw_text:\n",
    "    filtered_sentence = \"\"\n",
    "    stemmed_list = []\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    sentence = str(t)\n",
    "    \n",
    "    #Data Cleansing\n",
    "    sentence = re.sub(r'[^\\w\\s]', ' ', sentence)\n",
    "    \n",
    "    #Tokenization\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    #Stop words removal\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    #Stemming\n",
    "    for word in words:\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        stemmed_list.append(stemmed_word)\n",
    "        \n",
    "    #Lemmatization\n",
    "    for s_word in stemmed_list:\n",
    "        lemmatized_word = lemmatizer.lemmatize(s_word)\n",
    "        lemmatized_list.append(lemmatized_word)\n",
    "    \n",
    "    #Bigram Formation\n",
    "    bigrams = list(nltk.bigrams(lemmatized_list))\n",
    "    bigram_text=[\" \".join(t) for t in bigrams]\n",
    "    \n",
    "    filtered_text.append(bigram_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1843"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_text[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERTING DATA TO PANDAS DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_head = [\"Raw Data\", \"Processed Data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Data</th>\n",
       "      <th>Processed Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2021 Coachmen Sportscoach 402TS Two Full Bath...</td>\n",
       "      <td>[2021 coachman, coachman sportscoach, sportsco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Our Online Privacy Policy Skip to main conten...</td>\n",
       "      <td>[our onlin, onlin privaci, privaci polici, pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Python: parsing PDF text and tables - usage a...</td>\n",
       "      <td>[python par, par pdf, pdf text, text tabl, tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Arts vs. Athletics: Two Great Ways You Can Pr...</td>\n",
       "      <td>[art v, v athlet, athlet two, two great, great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Bubble Gum Pop Hat | AllFreeCrochet.com close...</td>\n",
       "      <td>[bubbl gum, gum pop, pop hat, hat allfreecroch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Transitional Care Gets a Room of Its Own - Pa...</td>\n",
       "      <td>[transit care, care get, get room, room it, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Decorative Objects/Accessories - Page 2 of 12...</td>\n",
       "      <td>[decor object, object accessori, accessori pag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Home About us Approach Family Office Purposef...</td>\n",
       "      <td>[home about, about u, u approach, approach fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Jemarl Baker Jr. to transfer from Arizona Wil...</td>\n",
       "      <td>[jemarl baker, baker Jr, Jr transfer, transfer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Publications | The Protect Heritage Corp. \\r,...</td>\n",
       "      <td>[public the, the protect, protect heritag, her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Raw Data  \\\n",
       "0  [2021 Coachmen Sportscoach 402TS Two Full Bath...   \n",
       "1  [Our Online Privacy Policy Skip to main conten...   \n",
       "2  [Python: parsing PDF text and tables - usage a...   \n",
       "3  [Arts vs. Athletics: Two Great Ways You Can Pr...   \n",
       "4  [Bubble Gum Pop Hat | AllFreeCrochet.com close...   \n",
       "5  [Transitional Care Gets a Room of Its Own - Pa...   \n",
       "6  [Decorative Objects/Accessories - Page 2 of 12...   \n",
       "7  [Home About us Approach Family Office Purposef...   \n",
       "8  [Jemarl Baker Jr. to transfer from Arizona Wil...   \n",
       "9  [Publications | The Protect Heritage Corp. \\r,...   \n",
       "\n",
       "                                      Processed Data  \n",
       "0  [2021 coachman, coachman sportscoach, sportsco...  \n",
       "1  [our onlin, onlin privaci, privaci polici, pol...  \n",
       "2  [python par, par pdf, pdf text, text tabl, tab...  \n",
       "3  [art v, v athlet, athlet two, two great, great...  \n",
       "4  [bubbl gum, gum pop, pop hat, hat allfreecroch...  \n",
       "5  [transit care, care get, get room, room it, it...  \n",
       "6  [decor object, object accessori, accessori pag...  \n",
       "7  [home about, about u, u approach, approach fam...  \n",
       "8  [jemarl baker, baker Jr, Jr transfer, transfer...  \n",
       "9  [public the, the protect, protect heritag, her...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.DataFrame(zip(raw_text,filtered_text), columns = table_head)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBEDDING TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "BoW_list = []\n",
    "for i in range(10):\n",
    "    x = vec.fit_transform(filtered_text[i])\n",
    "    BoW_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<552x292 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 1058 stored elements in Compressed Sparse Row format>,\n",
       " <1070x339 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 2106 stored elements in Compressed Sparse Row format>,\n",
       " <557x252 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 1064 stored elements in Compressed Sparse Row format>,\n",
       " <1961x664 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 3823 stored elements in Compressed Sparse Row format>,\n",
       " <3052x844 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 5805 stored elements in Compressed Sparse Row format>,\n",
       " <1079x470 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 2140 stored elements in Compressed Sparse Row format>,\n",
       " <1091x226 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 2140 stored elements in Compressed Sparse Row format>,\n",
       " <270x164 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 518 stored elements in Compressed Sparse Row format>,\n",
       " <867x292 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 1696 stored elements in Compressed Sparse Row format>,\n",
       " <1843x667 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 3331 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BoW_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Data</th>\n",
       "      <th>Processed Data</th>\n",
       "      <th>Bag of Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2021 Coachmen Sportscoach 402TS Two Full Bath...</td>\n",
       "      <td>[2021 coachman, coachman sportscoach, sportsco...</td>\n",
       "      <td>(0, 10)\\t1\\n  (0, 67)\\t1\\n  (1, 67)\\t1\\n  (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Our Online Privacy Policy Skip to main conten...</td>\n",
       "      <td>[our onlin, onlin privaci, privaci polici, pol...</td>\n",
       "      <td>(0, 214)\\t1\\n  (0, 211)\\t1\\n  (1, 211)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Python: parsing PDF text and tables - usage a...</td>\n",
       "      <td>[python par, par pdf, pdf text, text tabl, tab...</td>\n",
       "      <td>(0, 187)\\t1\\n  (0, 169)\\t1\\n  (1, 169)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Arts vs. Athletics: Two Great Ways You Can Pr...</td>\n",
       "      <td>[art v, v athlet, athlet two, two great, great...</td>\n",
       "      <td>(0, 56)\\t1\\n  (1, 63)\\t1\\n  (2, 63)\\t1\\n  (2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Bubble Gum Pop Hat | AllFreeCrochet.com close...</td>\n",
       "      <td>[bubbl gum, gum pop, pop hat, hat allfreecroch...</td>\n",
       "      <td>(0, 136)\\t1\\n  (0, 351)\\t1\\n  (1, 351)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Transitional Care Gets a Room of Its Own - Pa...</td>\n",
       "      <td>[transit care, care get, get room, room it, it...</td>\n",
       "      <td>(0, 424)\\t1\\n  (0, 72)\\t1\\n  (1, 72)\\t1\\n  (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Decorative Objects/Accessories - Page 2 of 12...</td>\n",
       "      <td>[decor object, object accessori, accessori pag...</td>\n",
       "      <td>(0, 73)\\t1\\n  (0, 145)\\t1\\n  (1, 145)\\t1\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Home About us Approach Family Office Purposef...</td>\n",
       "      <td>[home about, about u, u approach, approach fam...</td>\n",
       "      <td>(0, 67)\\t1\\n  (0, 0)\\t1\\n  (1, 0)\\t1\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Jemarl Baker Jr. to transfer from Arizona Wil...</td>\n",
       "      <td>[jemarl baker, baker Jr, Jr transfer, transfer...</td>\n",
       "      <td>(0, 143)\\t1\\n  (0, 52)\\t1\\n  (1, 52)\\t1\\n  (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Publications | The Protect Heritage Corp. \\r,...</td>\n",
       "      <td>[public the, the protect, protect heritag, her...</td>\n",
       "      <td>(0, 501)\\t1\\n  (0, 601)\\t1\\n  (1, 601)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Raw Data  \\\n",
       "0  [2021 Coachmen Sportscoach 402TS Two Full Bath...   \n",
       "1  [Our Online Privacy Policy Skip to main conten...   \n",
       "2  [Python: parsing PDF text and tables - usage a...   \n",
       "3  [Arts vs. Athletics: Two Great Ways You Can Pr...   \n",
       "4  [Bubble Gum Pop Hat | AllFreeCrochet.com close...   \n",
       "5  [Transitional Care Gets a Room of Its Own - Pa...   \n",
       "6  [Decorative Objects/Accessories - Page 2 of 12...   \n",
       "7  [Home About us Approach Family Office Purposef...   \n",
       "8  [Jemarl Baker Jr. to transfer from Arizona Wil...   \n",
       "9  [Publications | The Protect Heritage Corp. \\r,...   \n",
       "\n",
       "                                      Processed Data  \\\n",
       "0  [2021 coachman, coachman sportscoach, sportsco...   \n",
       "1  [our onlin, onlin privaci, privaci polici, pol...   \n",
       "2  [python par, par pdf, pdf text, text tabl, tab...   \n",
       "3  [art v, v athlet, athlet two, two great, great...   \n",
       "4  [bubbl gum, gum pop, pop hat, hat allfreecroch...   \n",
       "5  [transit care, care get, get room, room it, it...   \n",
       "6  [decor object, object accessori, accessori pag...   \n",
       "7  [home about, about u, u approach, approach fam...   \n",
       "8  [jemarl baker, baker Jr, Jr transfer, transfer...   \n",
       "9  [public the, the protect, protect heritag, her...   \n",
       "\n",
       "                                        Bag of Words  \n",
       "0    (0, 10)\\t1\\n  (0, 67)\\t1\\n  (1, 67)\\t1\\n  (1...  \n",
       "1    (0, 214)\\t1\\n  (0, 211)\\t1\\n  (1, 211)\\t1\\n ...  \n",
       "2    (0, 187)\\t1\\n  (0, 169)\\t1\\n  (1, 169)\\t1\\n ...  \n",
       "3    (0, 56)\\t1\\n  (1, 63)\\t1\\n  (2, 63)\\t1\\n  (2...  \n",
       "4    (0, 136)\\t1\\n  (0, 351)\\t1\\n  (1, 351)\\t1\\n ...  \n",
       "5    (0, 424)\\t1\\n  (0, 72)\\t1\\n  (1, 72)\\t1\\n  (...  \n",
       "6    (0, 73)\\t1\\n  (0, 145)\\t1\\n  (1, 145)\\t1\\n  ...  \n",
       "7    (0, 67)\\t1\\n  (0, 0)\\t1\\n  (1, 0)\\t1\\n  (2, ...  \n",
       "8    (0, 143)\\t1\\n  (0, 52)\\t1\\n  (1, 52)\\t1\\n  (...  \n",
       "9    (0, 501)\\t1\\n  (0, 601)\\t1\\n  (1, 601)\\t1\\n ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_head.append(\"Bag of Words\")\n",
    "df_data = pd.DataFrame(zip(raw_text,filtered_text, BoW_list), columns = table_head)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "Tfidf_list = []\n",
    "for i in range(10):\n",
    "    x = vectorizer.fit_transform(filtered_text[i])\n",
    "    Tfidf_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<552x292 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1058 stored elements in Compressed Sparse Row format>,\n",
       " <1070x339 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 2106 stored elements in Compressed Sparse Row format>,\n",
       " <557x252 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1064 stored elements in Compressed Sparse Row format>,\n",
       " <1961x664 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 3823 stored elements in Compressed Sparse Row format>,\n",
       " <3052x844 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 5805 stored elements in Compressed Sparse Row format>,\n",
       " <1079x470 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 2140 stored elements in Compressed Sparse Row format>,\n",
       " <1091x226 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 2140 stored elements in Compressed Sparse Row format>,\n",
       " <270x164 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 518 stored elements in Compressed Sparse Row format>,\n",
       " <867x292 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1696 stored elements in Compressed Sparse Row format>,\n",
       " <1843x667 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 3331 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tfidf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Tfidf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Data</th>\n",
       "      <th>Processed Data</th>\n",
       "      <th>Bag of Words</th>\n",
       "      <th>Tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2021 Coachmen Sportscoach 402TS Two Full Bath...</td>\n",
       "      <td>[2021 coachman, coachman sportscoach, sportsco...</td>\n",
       "      <td>(0, 10)\\t1\\n  (0, 67)\\t1\\n  (1, 67)\\t1\\n  (1...</td>\n",
       "      <td>(0, 67)\\t0.6934178959879685\\n  (0, 10)\\t0.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Our Online Privacy Policy Skip to main conten...</td>\n",
       "      <td>[our onlin, onlin privaci, privaci polici, pol...</td>\n",
       "      <td>(0, 214)\\t1\\n  (0, 211)\\t1\\n  (1, 211)\\t1\\n ...</td>\n",
       "      <td>(0, 211)\\t0.6872192264199813\\n  (0, 214)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Python: parsing PDF text and tables - usage a...</td>\n",
       "      <td>[python par, par pdf, pdf text, text tabl, tab...</td>\n",
       "      <td>(0, 187)\\t1\\n  (0, 169)\\t1\\n  (1, 169)\\t1\\n ...</td>\n",
       "      <td>(0, 169)\\t0.8221531853387946\\n  (0, 187)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Arts vs. Athletics: Two Great Ways You Can Pr...</td>\n",
       "      <td>[art v, v athlet, athlet two, two great, great...</td>\n",
       "      <td>(0, 56)\\t1\\n  (1, 63)\\t1\\n  (2, 63)\\t1\\n  (2...</td>\n",
       "      <td>(0, 56)\\t1.0\\n  (1, 63)\\t1.0\\n  (2, 610)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Bubble Gum Pop Hat | AllFreeCrochet.com close...</td>\n",
       "      <td>[bubbl gum, gum pop, pop hat, hat allfreecroch...</td>\n",
       "      <td>(0, 136)\\t1\\n  (0, 351)\\t1\\n  (1, 351)\\t1\\n ...</td>\n",
       "      <td>(0, 351)\\t0.7047811753225802\\n  (0, 136)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Transitional Care Gets a Room of Its Own - Pa...</td>\n",
       "      <td>[transit care, care get, get room, room it, it...</td>\n",
       "      <td>(0, 424)\\t1\\n  (0, 72)\\t1\\n  (1, 72)\\t1\\n  (...</td>\n",
       "      <td>(0, 72)\\t0.6613492853098424\\n  (0, 424)\\t0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Decorative Objects/Accessories - Page 2 of 12...</td>\n",
       "      <td>[decor object, object accessori, accessori pag...</td>\n",
       "      <td>(0, 73)\\t1\\n  (0, 145)\\t1\\n  (1, 145)\\t1\\n  ...</td>\n",
       "      <td>(0, 145)\\t0.7391952538944243\\n  (0, 73)\\t0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Home About us Approach Family Office Purposef...</td>\n",
       "      <td>[home about, about u, u approach, approach fam...</td>\n",
       "      <td>(0, 67)\\t1\\n  (0, 0)\\t1\\n  (1, 0)\\t1\\n  (2, ...</td>\n",
       "      <td>(0, 0)\\t0.6914852473085188\\n  (0, 67)\\t0.722...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Jemarl Baker Jr. to transfer from Arizona Wil...</td>\n",
       "      <td>[jemarl baker, baker Jr, Jr transfer, transfer...</td>\n",
       "      <td>(0, 143)\\t1\\n  (0, 52)\\t1\\n  (1, 52)\\t1\\n  (...</td>\n",
       "      <td>(0, 52)\\t0.6732948905294239\\n  (0, 143)\\t0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Publications | The Protect Heritage Corp. \\r,...</td>\n",
       "      <td>[public the, the protect, protect heritag, her...</td>\n",
       "      <td>(0, 501)\\t1\\n  (0, 601)\\t1\\n  (1, 601)\\t1\\n ...</td>\n",
       "      <td>(0, 601)\\t0.6590000178652068\\n  (0, 501)\\t0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Raw Data  \\\n",
       "0  [2021 Coachmen Sportscoach 402TS Two Full Bath...   \n",
       "1  [Our Online Privacy Policy Skip to main conten...   \n",
       "2  [Python: parsing PDF text and tables - usage a...   \n",
       "3  [Arts vs. Athletics: Two Great Ways You Can Pr...   \n",
       "4  [Bubble Gum Pop Hat | AllFreeCrochet.com close...   \n",
       "5  [Transitional Care Gets a Room of Its Own - Pa...   \n",
       "6  [Decorative Objects/Accessories - Page 2 of 12...   \n",
       "7  [Home About us Approach Family Office Purposef...   \n",
       "8  [Jemarl Baker Jr. to transfer from Arizona Wil...   \n",
       "9  [Publications | The Protect Heritage Corp. \\r,...   \n",
       "\n",
       "                                      Processed Data  \\\n",
       "0  [2021 coachman, coachman sportscoach, sportsco...   \n",
       "1  [our onlin, onlin privaci, privaci polici, pol...   \n",
       "2  [python par, par pdf, pdf text, text tabl, tab...   \n",
       "3  [art v, v athlet, athlet two, two great, great...   \n",
       "4  [bubbl gum, gum pop, pop hat, hat allfreecroch...   \n",
       "5  [transit care, care get, get room, room it, it...   \n",
       "6  [decor object, object accessori, accessori pag...   \n",
       "7  [home about, about u, u approach, approach fam...   \n",
       "8  [jemarl baker, baker Jr, Jr transfer, transfer...   \n",
       "9  [public the, the protect, protect heritag, her...   \n",
       "\n",
       "                                        Bag of Words  \\\n",
       "0    (0, 10)\\t1\\n  (0, 67)\\t1\\n  (1, 67)\\t1\\n  (1...   \n",
       "1    (0, 214)\\t1\\n  (0, 211)\\t1\\n  (1, 211)\\t1\\n ...   \n",
       "2    (0, 187)\\t1\\n  (0, 169)\\t1\\n  (1, 169)\\t1\\n ...   \n",
       "3    (0, 56)\\t1\\n  (1, 63)\\t1\\n  (2, 63)\\t1\\n  (2...   \n",
       "4    (0, 136)\\t1\\n  (0, 351)\\t1\\n  (1, 351)\\t1\\n ...   \n",
       "5    (0, 424)\\t1\\n  (0, 72)\\t1\\n  (1, 72)\\t1\\n  (...   \n",
       "6    (0, 73)\\t1\\n  (0, 145)\\t1\\n  (1, 145)\\t1\\n  ...   \n",
       "7    (0, 67)\\t1\\n  (0, 0)\\t1\\n  (1, 0)\\t1\\n  (2, ...   \n",
       "8    (0, 143)\\t1\\n  (0, 52)\\t1\\n  (1, 52)\\t1\\n  (...   \n",
       "9    (0, 501)\\t1\\n  (0, 601)\\t1\\n  (1, 601)\\t1\\n ...   \n",
       "\n",
       "                                               Tfidf  \n",
       "0    (0, 67)\\t0.6934178959879685\\n  (0, 10)\\t0.72...  \n",
       "1    (0, 211)\\t0.6872192264199813\\n  (0, 214)\\t0....  \n",
       "2    (0, 169)\\t0.8221531853387946\\n  (0, 187)\\t0....  \n",
       "3    (0, 56)\\t1.0\\n  (1, 63)\\t1.0\\n  (2, 610)\\t0....  \n",
       "4    (0, 351)\\t0.7047811753225802\\n  (0, 136)\\t0....  \n",
       "5    (0, 72)\\t0.6613492853098424\\n  (0, 424)\\t0.7...  \n",
       "6    (0, 145)\\t0.7391952538944243\\n  (0, 73)\\t0.6...  \n",
       "7    (0, 0)\\t0.6914852473085188\\n  (0, 67)\\t0.722...  \n",
       "8    (0, 52)\\t0.6732948905294239\\n  (0, 143)\\t0.7...  \n",
       "9    (0, 601)\\t0.6590000178652068\\n  (0, 501)\\t0....  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_head.append(\"Tfidf\")\n",
    "df_data = pd.DataFrame(zip(raw_text,filtered_text, BoW_list, Tfidf_list), columns = table_head)\n",
    "df_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
